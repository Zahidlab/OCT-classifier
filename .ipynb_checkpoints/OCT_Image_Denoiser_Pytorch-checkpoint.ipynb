{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Zahidlab/OCT-Image-Denoising/blob/main/OCT_Image_Denoiser_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0.dev20230313'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6bL7X8Aqu_Mg"
   },
   "outputs": [],
   "source": [
    "# !zip -r /content/patchOCT.zip /content/drive/MyDrive/Research/'OCT datasets'/'Patch OCT Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AoWLmqbn-hN",
    "outputId": "91a99ae6-4054-4b41-daca-d93da5c3dbe1"
   },
   "outputs": [],
   "source": [
    "# !unzip '/content/Patch OCT Dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fmRcuBsjpoO1"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os.path import join, isdir\n",
    "from os import mkdir, makedirs\n",
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A055G4iYmdGV",
    "outputId": "8ee8e903-5246-43aa-8725-358e739529fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Current Device: None\n"
     ]
    }
   ],
   "source": [
    "# Find Out if the code is running in Google Colab\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "#setting up Device for device agnostic code\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Current Device: {print(DEVICE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWVvjX6hnGaS",
    "outputId": "cc7dc212-811d-4208-bde7-a2a6e77415ec"
   },
   "outputs": [],
   "source": [
    "#Mounting Google Drive and setting the Root Data Directory for Colab Environment\n",
    "\n",
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  \n",
    "  # Defining Data Path\n",
    "  Root_Dir = '/content/drive/MyDrive/Research/OCT datasets'\n",
    "\n",
    "  url = \"https://drive.google.com/uc?id=1VLaDBx7MU4ZzPOQGnxRjuEP-flF54FiW\"\n",
    "\n",
    "  import gdown\n",
    "  output = '20150428_collected_images.tgz'\n",
    "  gdown.download(url, output, quiet=False)\n",
    "  # gdown.download(url, output = 'oct_patch')\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7wHx7xEfotNg"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Root_Dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setting Specific data path for each different data folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m first_first \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mRoot_Dir\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFast Acuisition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor synthetic experiments\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m first_second \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(Root_Dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFast Acuisition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImages for Dictionaries and Mapping leraning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m second \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(Root_Dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparsity Based Denoising... _SDOCT_DATASET_2012_AMD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Root_Dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting Specific data path for each different data folder\n",
    "first_first = os.path.join(Root_Dir,'Fast Acuisition', 'For synthetic experiments')\n",
    "first_second = os.path.join(Root_Dir,'Fast Acuisition', 'Images for Dictionaries and Mapping leraning')\n",
    "second = os.path.join(Root_Dir, 'Sparsity Based Denoising... _SDOCT_DATASET_2012_AMD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ayUkJLHbGHU"
   },
   "source": [
    "## Importing 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQODa-Z6qPaW"
   },
   "outputs": [],
   "source": [
    "# # First First\n",
    "# CLEAN_IMAGES = []\n",
    "# NOISY_IMAGES = []\n",
    "# IMAGE_PATHS = []\n",
    "# for folder in os.listdir(first_first):\n",
    "#   folder_path = os.path.join(first_first, folder)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "#   clean_img_path = join(folder_path, 'average.tif')\n",
    "#   noisy_image_path = join(folder_path, '1.tif')\n",
    "\n",
    "#   IMAGE_PATHS.append([noisy_image_path, clean_img_path, 'FAFSE'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQEjoUrBke7z"
   },
   "outputs": [],
   "source": [
    "# # second dataset\n",
    "# # IMAGE_PATHS = []\n",
    "# for folder in sorted(os.listdir(second)):\n",
    "\n",
    "#   folder_path = os.path.join(second, folder)\n",
    "\n",
    "#   if os.path.isfile(folder_path):\n",
    "#     continue\n",
    "  \n",
    "\n",
    "#   for img in os.listdir(folder_path):\n",
    "#     if 'Averaged' in img:\n",
    "\n",
    "#       clean_img_path = join(folder_path, img)\n",
    "#     elif 'Raw' in img:\n",
    "\n",
    "#       noisy_image_path = join(folder_path, img)\n",
    "\n",
    "#   IMAGE_PATHS.append([noisy_image_path, clean_img_path, 'FAIFD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvC8m1597k48"
   },
   "outputs": [],
   "source": [
    "# # First Second\n",
    "# print(first_second)\n",
    "# # Img_paths = []\n",
    "# for i in range(1,11):\n",
    "#   clean_image_path = join(first_second, f'HH{i}.tif')\n",
    "\n",
    "#   noisy_image_path = join(first_second, f'LL{i}.tif')\n",
    "\n",
    "#   IMAGE_PATHS.append([noisy_image_path, clean_image_path, 'SBD'])\n",
    "\n",
    "# # Img_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gcip_RyTsFa8"
   },
   "source": [
    "### deleting contents of a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOjBnED9rRtM"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "def del_contents(path):\n",
    "  folder = path\n",
    "  for filename in os.listdir(folder):\n",
    "      file_path = os.path.join(folder, filename)\n",
    "      try:\n",
    "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "              os.unlink(file_path)\n",
    "          elif os.path.isdir(file_path):\n",
    "              shutil.rmtree(file_path)\n",
    "      except Exception as e:\n",
    "          print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPjlUov_bBgU"
   },
   "source": [
    "## Saving Images in a single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDDqdSEo-ffk"
   },
   "outputs": [],
   "source": [
    "# # Saving Images in a single folder\n",
    "# root_dir = '/content/drive/MyDrive/Research/OCT datasets/Organised Dataset'\n",
    "# dir = root_dir\n",
    "# if isdir(root_dir):\n",
    "#   del_contents(root_dir)\n",
    "# else:\n",
    "#   mkdir(root_dir)\n",
    "# clean_dir = join(root_dir, 'Clean')\n",
    "# noisy_dir = join(root_dir, 'Noisy')\n",
    "\n",
    "# if not os.path.isdir(clean_dir):\n",
    "#   os.mkdir(clean_dir)\n",
    "#   os.mkdir(noisy_dir)\n",
    "\n",
    "# index = 1\n",
    "# for n,c,ds in IMAGE_PATHS:\n",
    "\n",
    "#   folder_name = f\"{index:03d} {ds}\"\n",
    "\n",
    "#   clean_folder_path = join(clean_dir, folder_name)\n",
    "\n",
    "#   if not os.path.isdir(clean_folder_path):\n",
    "#     os.mkdir(clean_folder_path)\n",
    "\n",
    "#   file_name = f\"{index:03d} {ds}.jpg\"\n",
    "#   clean_image_path = join(clean_folder_path, file_name)\n",
    "#   shutil.copy(c, clean_image_path)\n",
    "\n",
    "#   ######################\n",
    "\n",
    "#   noisy_folder_path = join(noisy_dir, folder_name)\n",
    "\n",
    "#   if not os.path.isdir(noisy_folder_path):\n",
    "#     os.mkdir(noisy_folder_path)\n",
    "\n",
    "#   file_name = f\"{index:03d} {ds}.jpg\"\n",
    "#   noisy_image_path = join(noisy_folder_path, file_name)\n",
    "#   shutil.copy(n, noisy_image_path)\n",
    "\n",
    "\n",
    "#   index+=1\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpVHFeNxmJF7"
   },
   "outputs": [],
   "source": [
    "# len(IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTXwtJyBX0RQ"
   },
   "source": [
    "## Creating Image Patchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsdfL5IpVk5N"
   },
   "outputs": [],
   "source": [
    "# # Creating Image Paths\n",
    "\n",
    "# PATCH_SIZE = 64\n",
    "\n",
    "# patch_root_dir = \"/content/drive/MyDrive/Research/OCT datasets/Patch OCT Dataset\"\n",
    "\n",
    "# if isdir(patch_root_dir):\n",
    "#   del_contents(patch_root_dir)\n",
    "# else:\n",
    "#   os.mkdir(patch_root_dir)\n",
    "\n",
    "# clean_patch_dir = join(patch_root_dir, 'Clean')\n",
    "# noisy_patch_dir = join(patch_root_dir, 'Noisy')\n",
    "\n",
    "# if not isdir(clean_patch_dir):\n",
    "#   makedirs(clean_patch_dir)\n",
    "#   makedirs(noisy_patch_dir)\n",
    "\n",
    "# patch_list = []\n",
    "\n",
    "# clean_raw_image_dir = '/content/drive/MyDrive/Research/OCT datasets/Organised Dataset/Clean'\n",
    "# noisy_raw_image_dir = '/content/drive/MyDrive/Research/OCT datasets/Organised Dataset/Noisy'\n",
    "\n",
    "# for folder in sorted(os.listdir(clean_raw_image_dir)):\n",
    "#   clean_image_path = join(clean_raw_image_dir, folder, folder+'.jpg')\n",
    "#   noisy_image_path = join(noisy_raw_image_dir, folder, folder+'.jpg')\n",
    "\n",
    "#   clean_image = cv2.imread(clean_image_path,0)\n",
    "#   noisy_image = cv2.imread(noisy_image_path, 0)\n",
    "\n",
    "#   if(clean_image.shape != noisy_image.shape):\n",
    "#     print(f\"Shape mismatch {clean_image.shape} - {noisy_image.shape} - {folder}\")\n",
    "\n",
    "#   height, width = clean_image.shape\n",
    "\n",
    "#   clean_patch_folder_path = join(clean_patch_dir, folder)\n",
    "#   noisy_patch_folder_path = join(noisy_patch_dir, folder)\n",
    "#   mkdir(clean_patch_folder_path)\n",
    "#   mkdir(noisy_patch_folder_path)\n",
    "#   index = 1\n",
    "#   for h in range(height//PATCH_SIZE):\n",
    "#     # print(i)\n",
    "#     for w in range(width//PATCH_SIZE):\n",
    "#       # print(f\"j = {j}\")\n",
    "#       clean_patch = clean_image[h*PATCH_SIZE:(h+1)*PATCH_SIZE , w*PATCH_SIZE:(w+1)*PATCH_SIZE , ]\n",
    "#       clean_patch_image_path = join(clean_patch_folder_path, f\"{index:03d}.jpg\")\n",
    "#       cv2.imwrite(clean_patch_image_path, clean_patch)\n",
    "#       ######################\n",
    "#       noisy_patch = noisy_image[h*PATCH_SIZE:(h+1)*PATCH_SIZE , w*PATCH_SIZE:(w+1)*PATCH_SIZE , ]\n",
    "#       noisy_patch_image_path = join(noisy_patch_folder_path, f\"{index:03d}.jpg\")\n",
    "#       cv2.imwrite(noisy_patch_image_path, noisy_patch)\n",
    "\n",
    "#       # print(clean_patch_image_path, noisy_patch_image_path)\n",
    "\n",
    "\n",
    "#       patch_list.append([noisy_patch, clean_patch])\n",
    "#       index+=1\n",
    "\n",
    "#       # plt.subplot(1,2,1)\n",
    "#       # plt.imshow(noisy_patch, cmap='gray')\n",
    "#       # plt.subplot(1,2,2)\n",
    "#       # plt.imshow(clean_patch, cmap='gray')\n",
    "#   #     break\n",
    "#   #   break\n",
    "#   # break\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8lifkJ3V3G6"
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gnyf-vstBJ8s"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  patch_data_dir = '/content/Patch OCT Dataset'\n",
    "elif DEVICE=='mps':\n",
    "  patch_data_dir ='/Users/zahidulislam/Documents/Research/OCT Image Denoising/Patch OCT Dataset/'\n",
    "\n",
    "# !unzip '/content/drive/MyDrive/Research/OCT datasets/Patch OCT Dataset.zip'\n",
    "clean_data_dir = join(patch_data_dir, 'Clean')\n",
    "noisy_data_dir = join(patch_data_dir, 'Noisy')\n",
    "IMAGE_PATHS = []\n",
    "\n",
    "for folder in sorted(os.listdir(clean_data_dir)):\n",
    "  # print(folder)\n",
    "  clean_folder_path = join(clean_data_dir, folder)\n",
    "  noisy_folder_path = join(noisy_data_dir, folder)\n",
    "  # print(current_folder_path)\n",
    "  for img in sorted(os.listdir(clean_folder_path)):\n",
    "    # print(img)\n",
    "\n",
    "    clean_img_path = join(clean_folder_path, img)\n",
    "    noisy_img_path = join(noisy_folder_path, img)\n",
    "\n",
    "    IMAGE_PATHS.append([noisy_img_path, clean_img_path])\n",
    "    # print(clean_img_path, noisy_img_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsXahUnmnSej",
    "outputId": "9eb04767-4004-4165-b955-6bac91cf8705"
   },
   "outputs": [],
   "source": [
    "len(IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXgJvjTzZOuF"
   },
   "source": [
    "#  Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWReRdgAZavz"
   },
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ESKqrRhZHyI"
   },
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esaUkDNEz5C2"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, paths, transform = None):\n",
    "    self.paths = paths\n",
    "    self.transform = transform\n",
    "\n",
    "  def __getitem__(self, index:int, ):\n",
    "\n",
    "    noisy_img = Image.open(self.paths[index][0])\n",
    "    clean_img = Image.open(self.paths[index][1])\n",
    "    # clean_img = transforms.functional.adjust_sharpness(clean_img,sharpness_factor=10)\n",
    "\n",
    "    if self.transform:\n",
    "      return self.transform(noisy_img), self.transform(clean_img)\n",
    "\n",
    "    return noisy_img, clean_img\n",
    "\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRvBb74zZgJI"
   },
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSX09R8L6hSt"
   },
   "outputs": [],
   "source": [
    "# defining Transforms Needed to be done on the Images\n",
    "trans = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    # transforms.Resize((128,128)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGYGQSc0Zi61"
   },
   "source": [
    "### Dataset Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-4k7fgk3xIy",
    "outputId": "3bd14f24-8786-44df-f697-334860f640c7"
   },
   "outputs": [],
   "source": [
    "# Dataset \n",
    "dataset = CustomDataset(IMAGE_PATHS, transform = trans)\n",
    "print(f\"Total Pair Of Images: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "PEKmRxJY-J_2",
    "outputId": "7f48520c-92c0-4ba4-b883-229d76544230"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,18))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(dataset[1][0].squeeze(), cmap = 'gray')\n",
    "plt.title('Noisy Image')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dataset[1][1].squeeze(), cmap = 'gray')\n",
    "plt.title('Clean Image')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "n,c = dataset[1][0], dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGTGbilb86rY"
   },
   "source": [
    "## BATCH SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRvWrJXh8-b1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yccvZVV_Whs"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3kfsqfIpBvN",
    "outputId": "652261c2-07e1-47af-f2a3-f0a970f7f07f"
   },
   "outputs": [],
   "source": [
    "start_time = timer()\n",
    "r = torch.tensor([32,1,64,64], device = DEVICE)\n",
    "print(timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksV8x3G34Vg8"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pup74pzfzeKK"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/OCT Denoise/first try')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpcwDon__Z0t"
   },
   "source": [
    "# Model Creation and Training Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSjwDmfs_e7o"
   },
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hx2hNFHk9VyE"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # decoder layers\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "\n",
    "    self.apply(self._init_weights)\n",
    "\n",
    "  def _init_weights(self, module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "      module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "      if module.bias is not None:\n",
    "          module.bias.data.zero_()\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    # print(encoded.shape)\n",
    "    # print(f\"Shape of encoded: {encoded.shape}\")\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STH30FOvLGbS"
   },
   "source": [
    "### Test Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJRQzhsBGhRM"
   },
   "outputs": [],
   "source": [
    "rand_img = torch.randn([32, 1, 64, 64])\n",
    "rand_img.shape\n",
    "generator = Generator()\n",
    "\n",
    "result = generator(rand_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "SFNXpOK_J8g2",
    "outputId": "8cfc9975-bf7c-4694-f804-1f932f30002e"
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(DEVICE)\n",
    "\n",
    "x = n.unsqueeze(dim=1)\n",
    "\n",
    "result = generator(x.to(DEVICE))\n",
    "print(result.shape)\n",
    "with torch.inference_mode():\n",
    "  plt.imshow(result.squeeze().to('cpu'), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "ucUZwkAiX1Oe",
    "outputId": "33fef276-7a98-423d-e8bc-cb438e609f1f"
   },
   "outputs": [],
   "source": [
    "test_noisy_image = n.to(DEVICE)\n",
    "gen_clean_image = generator(test_noisy_image.unsqueeze(dim=1)).squeeze()\n",
    "real_clean_image = c\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "with torch.inference_mode():\n",
    "  fig.add_subplot(1,3,1)\n",
    "  plt.imshow(test_noisy_image.squeeze().to('cpu'), cmap='gray')\n",
    "  plt.title(\"Real Noisy Image\")\n",
    "  plt.axis('off')\n",
    "\n",
    "  fig.add_subplot(1,3,2)\n",
    "  plt.imshow(gen_clean_image.to('cpu'), cmap='gray')\n",
    "  plt.title(\"Fake Clean Image: Not Trained\")\n",
    "  plt.axis('off')\n",
    "\n",
    "  fig.add_subplot(1,3,3)\n",
    "  plt.imshow(real_clean_image.squeeze().to('cpu'), cmap='gray')\n",
    "  plt.title(\"Real Clean Image\")\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWGunl6CKDnk"
   },
   "source": [
    "## Discriminitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toNh3P9QMe2-"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, input_shape, output_shape):\n",
    "    super().__init__()\n",
    "\n",
    "    self.block_1 = nn.Sequential(\n",
    "        \n",
    "        nn.Conv2d(\n",
    "            in_channels = input_shape, \n",
    "            out_channels = 64,\n",
    "            kernel_size = 3,\n",
    "            # padding=1,\n",
    "            # stride=1,\n",
    "        ),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size = 2,\n",
    "            # stride=2,\n",
    "        ),\n",
    "\n",
    "        # \n",
    "        nn.Conv2d(\n",
    "            in_channels = 64, \n",
    "            out_channels = 128,\n",
    "            kernel_size = 3,\n",
    "            # padding=1,\n",
    "            # stride=1,\n",
    "\n",
    "        ),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size = 2,\n",
    "            # stride=2,\n",
    "        ),\n",
    "        # \n",
    "        nn.Conv2d(\n",
    "            in_channels = 128, \n",
    "            out_channels = 256,\n",
    "            kernel_size = 3,\n",
    "            # padding=1,\n",
    "            # stride=1,\n",
    "\n",
    "        ),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size = 2,\n",
    "            # stride=2,\n",
    "        ),\n",
    "        # \n",
    "        nn.Conv2d(\n",
    "            in_channels = 256, \n",
    "            out_channels = 512,\n",
    "            kernel_size = 3,\n",
    "            # padding=1,\n",
    "            # stride=1,\n",
    "\n",
    "        ),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size = 2,\n",
    "            # stride=2,\n",
    "        ),\n",
    "\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = 512*2*2, out_features = 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 1024, out_features = output_shape)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.block_1(x)\n",
    "    # x = self.block_2(x)\n",
    "    # print(x.shape)\n",
    "    x = self.classifier(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUDu02I2LOrL"
   },
   "source": [
    "### Test Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tO41k3t9Gli0",
    "outputId": "c4449488-1b22-417d-f286-548193dcd503"
   },
   "outputs": [],
   "source": [
    "# Test Discriminator\n",
    "discriminator = Discriminator(1,1).to(DEVICE)\n",
    "x = torch.rand(size = [20,1,64,64]).to(DEVICE)\n",
    "\n",
    "r = discriminator(x)\n",
    "print(r.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG6V12NmKNBV"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHhKGtAf_tmC"
   },
   "outputs": [],
   "source": [
    "mseloss = nn.MSELoss()\n",
    "bceloss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "optim_d = torch.optim.Adam(discriminator.parameters(), lr = 0.001, weight_decay=1e-5)\n",
    "optim_g = torch.optim.Adam(generator.parameters(), lr = 0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfuPNLziWm1K"
   },
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sW1J6NyWxIH"
   },
   "source": [
    "### Show sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9Ib51BIpzvE"
   },
   "outputs": [],
   "source": [
    "def show_sample():\n",
    "  test_noisy_image = n.to(DEVICE)\n",
    "  gen_clean_image = generator(test_noisy_image.unsqueeze(dim=1)).squeeze()\n",
    "  real_clean_image = c\n",
    "\n",
    "  fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.imshow(test_noisy_image.squeeze().to('cpu'), cmap='gray')\n",
    "    plt.title(\"Real Noisy Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.imshow(gen_clean_image.to('cpu'), cmap='gray')\n",
    "    plt.title(\"Fake Clean Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.imshow(real_clean_image.squeeze(), cmap='gray')\n",
    "    plt.title(\"Real Clean Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5ntxNdTWzv6"
   },
   "source": [
    "### PSNR calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EgQt2LRX4Ha"
   },
   "outputs": [],
   "source": [
    "from math import log10,sqrt\n",
    "def PSNR(original, compressed):\n",
    "    mse = torch.mean((torch.sub(original, compressed)) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = torch.max(original)\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3pCrOaOLhf2"
   },
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gS__UndW4eu"
   },
   "source": [
    "### Discriminator Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQxmiKsnLkPX"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_discriminator(noisy_images, clean_images, optimizer_d):\n",
    "  optimizer_d.zero_grad()\n",
    "\n",
    "  preds_for_real = discriminator(clean_images)\n",
    "  targets_for_real = torch.ones(clean_images.size(0), 1, device = DEVICE)\n",
    "  \n",
    "  loss_for_real = bceloss(preds_for_real, targets_for_real)\n",
    "  real_score = torch.mean(preds_for_real).item()\n",
    "\n",
    "\n",
    "\n",
    "  fake_clean_images = generator(noisy_images)\n",
    "\n",
    "\n",
    "  preds_for_fake = discriminator(fake_clean_images)\n",
    "  targets_for_fake = torch.zeros(fake_clean_images.size(0), 1, device = DEVICE)\n",
    "\n",
    "  loss_for_fake = bceloss(preds_for_fake, targets_for_fake)\n",
    "\n",
    "  fake_score = torch.mean(preds_for_fake).item()\n",
    "\n",
    "  # diff_in_images = mseloss(clean_images, fake_clean_images)\n",
    "  # writer.add_scalar('Diff in Image', diff_in_images )\n",
    "  # print(f\"Disc Diff in Images: {diff_in_images}\")\n",
    "\n",
    "  loss = loss_for_real + loss_for_fake \n",
    "  # print(diff_in_images, loss_for_real, loss_for_fake)\n",
    "  \n",
    "  loss.backward()\n",
    "\n",
    "  optimizer_d.step()\n",
    "\n",
    "  return loss.item(), real_score, fake_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aCgXKAuW7Yr"
   },
   "source": [
    "### Generator Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arPrn3IxRP18"
   },
   "outputs": [],
   "source": [
    "def train_generator(noisy_images, real_images, optimizer_g):\n",
    "\n",
    "  optimizer_g.zero_grad()\n",
    "\n",
    "\n",
    "  fake_images = generator(noisy_images)\n",
    "\n",
    "  preds_for_fake = discriminator(fake_images)\n",
    "\n",
    "  false_targets_for_fake = torch.ones(fake_images.size(0), 1, device = DEVICE)\n",
    "  diff_in_images = mseloss(real_images, fake_images)\n",
    "  # print(f\"Diff in Images: {diff_in_images}\")\n",
    "  generator_loss = bceloss(preds_for_fake, false_targets_for_fake)\n",
    "\n",
    "  # total_loss = generator_loss \n",
    "  generator_loss.backward()\n",
    "  optimizer_g.step()\n",
    "\n",
    "  return generator_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCpuZGwQWanc"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yKFooss_3Un"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "Images = []\n",
    "def fit(EPOCHS, start_idx= 1):\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  Gen_Loss = []\n",
    "  Dis_Loss = []\n",
    "\n",
    "  Real_Scores = []\n",
    "  Fake_Scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    for noisy_images, clean_images in tqdm(train_dl):\n",
    "      noisy_images = noisy_images.to(DEVICE, non_blocking=True)\n",
    "      clean_images = clean_images.to(DEVICE, non_blocking=True)\n",
    "\n",
    "      loss_d, real_score, fake_score = train_discriminator(noisy_images, clean_images, optim_d)\n",
    "      loss_g = train_generator(noisy_images, clean_images, optim_g)\n",
    "\n",
    "      # optim_g.zero_grad(set_to_none=True)\n",
    "\n",
    "      # res = generator(noisy_images)\n",
    "      # psnr = PSNR(clean_images, res)\n",
    "      # loss = mseloss(res, clean_images)\n",
    "\n",
    "      # loss.backward()\n",
    "      # optim_g.step()\n",
    "\n",
    "\n",
    "    # print(loss.item())\n",
    "    # print(f\"EPOCH: {epoch+1} | MSE Loss: {loss.item():.4f} | PSNR: {psnr:.4f}\")\n",
    "    # writer.add_scalar('MSE LOSS', loss.item(), global_step = epoch+1)\n",
    "    # writer.add_scalar('PSNR', psnr, global_step = epoch+1)\n",
    "\n",
    "\n",
    "    Gen_Loss.append(loss_g)\n",
    "    Dis_Loss.append(loss_d)\n",
    "    writer.add_scalar('LOSS D', loss_d, global_step = epoch+1)\n",
    "    writer.add_scalar('LOSS G', loss_g, global_step = epoch+1)\n",
    "\n",
    "    Real_Scores.append(real_score)\n",
    "    Fake_Scores.append(fake_score)\n",
    "\n",
    "    # show_sample()\n",
    "    test_noisy_image = n.to(DEVICE)\n",
    "    gen_clean_image = generator(test_noisy_image.unsqueeze(dim=1)).squeeze()\n",
    "    real_clean_image = c\n",
    "\n",
    "    psnr = PSNR(real_clean_image, gen_clean_image)\n",
    "    writer.add_scalar('PSNR', psnr, global_step = epoch+1)\n",
    "    writer.add_image('Fake Clean Image', gen_clean_image, dataformats='HW')\n",
    "    Images.append([test_noisy_image.to('cpu'),gen_clean_image.to('cpu'), real_clean_image])\n",
    "\n",
    "    print(f\"EPOCH: {epoch+1} | Gen Loss: {loss_g:.4f} |  Dis Loss: {loss_d:.4f} | PSNR: {psnr:.4f} \\n\\n\")\n",
    "\n",
    "    # save_samples(epoch+start_idx, fixed_latent, show = False)\n",
    "  \n",
    "  return Gen_Loss, Dis_Loss, Real_Scores, Fake_Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTqLOXHqjPBd",
    "outputId": "b90f3874-3bf9-428e-a551-669adeeb3667"
   },
   "outputs": [],
   "source": [
    "PSNR(torch.rand([32,1,64,64]),torch.rand([32,1,64,64]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECcdv5JOWVBg"
   },
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ab37bf0904184563ad69e45be02a441a",
      "339ac17a450d4d18b556a374370821c9",
      "8594dd4b83414a0cb8b2e9133d544c98",
      "f7a69a9e642547fb962ddb99ea4bd1a0",
      "fe2b2f2d795640f0a805cc292303441c",
      "b954612735e84afbbb514760a7d88484",
      "0cedea0fa0ab437398ce0a8c7fa07681",
      "f58b1e5a541d4fbd88afc495a7c63178",
      "cb3bd4650dcf4f79b2caa6cce48607d5",
      "2430b9198c814ea499c5cb77b3c19c36",
      "b8139b417062491387dbb8ae1a2af397",
      "5c7189b819c64ddab1fb2492a380b691",
      "d443bd2a52294b7981e385876798a336",
      "345b6cea9ac946239526c894b8794bf5",
      "726689fbc57a484091bbf7157c49e567",
      "4de503e1a26a4c7b8b181cc60db2f460",
      "fe6af7d2b7c84c65828edf7dba7c494c",
      "65fe52f7f2cc498d95d15ffee087dde5",
      "97ae1940f1be4d948b8389b06fd95a89",
      "4e5da0d89a8c4f32b4e4e248f126f30c",
      "a3bb628c022b4e6ba6d46e27bd3a4533",
      "2add03aacfbd43769ef97a6f9c0304bf"
     ]
    },
    "id": "-_-yL6V0As72",
    "outputId": "f4bad791-8ba3-4eeb-c378-0dbcdafba9c7"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time = timer()\n",
    "history = fit(EPOCHS, )\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"\\nTotal Time Taken: {end_time-start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "troKCqGKeEkY"
   },
   "outputs": [],
   "source": [
    "show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep70m5EHmjOI"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 12))\n",
    "# plt.suptitle(\"Noisy-Fake-Clean\", fontsize=18, y=0.95)\n",
    "# cols = 3\n",
    "# rows = EPOCHS\n",
    "# with torch.inference_mode():\n",
    "#   index = 1\n",
    "#   for i in range(rows*cols):\n",
    "#     for j in range(3):\n",
    "#       if index>rows*cols:\n",
    "#         break\n",
    "#       plt.subplot(rows,cols,index) \n",
    "#       plt.imshow(Images[i][j].squeeze().to('cpu'), 'gray')\n",
    "#       index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2MQPx1i0lhv"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCbqTNZSSvtl"
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "model = models.resnet18()\n",
    "inputs = torch.randn(5, 3, 224, 224)\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "  with record_function(\"model_inference\"):\n",
    "    model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4wqsO/FgZlVgq7IRY/B/J",
   "collapsed_sections": [
    "9ayUkJLHbGHU",
    "lPjlUov_bBgU",
    "zTXwtJyBX0RQ",
    "JSjwDmfs_e7o",
    "STH30FOvLGbS",
    "EWGunl6CKDnk",
    "UG6V12NmKNBV",
    "EfuPNLziWm1K",
    "3sW1J6NyWxIH",
    "o5ntxNdTWzv6",
    "ECcdv5JOWVBg"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cedea0fa0ab437398ce0a8c7fa07681": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2430b9198c814ea499c5cb77b3c19c36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2add03aacfbd43769ef97a6f9c0304bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "339ac17a450d4d18b556a374370821c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b954612735e84afbbb514760a7d88484",
      "placeholder": "​",
      "style": "IPY_MODEL_0cedea0fa0ab437398ce0a8c7fa07681",
      "value": "  0%"
     }
    },
    "345b6cea9ac946239526c894b8794bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97ae1940f1be4d948b8389b06fd95a89",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e5da0d89a8c4f32b4e4e248f126f30c",
      "value": 0
     }
    },
    "4de503e1a26a4c7b8b181cc60db2f460": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5da0d89a8c4f32b4e4e248f126f30c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c7189b819c64ddab1fb2492a380b691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d443bd2a52294b7981e385876798a336",
       "IPY_MODEL_345b6cea9ac946239526c894b8794bf5",
       "IPY_MODEL_726689fbc57a484091bbf7157c49e567"
      ],
      "layout": "IPY_MODEL_4de503e1a26a4c7b8b181cc60db2f460"
     }
    },
    "65fe52f7f2cc498d95d15ffee087dde5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "726689fbc57a484091bbf7157c49e567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3bb628c022b4e6ba6d46e27bd3a4533",
      "placeholder": "​",
      "style": "IPY_MODEL_2add03aacfbd43769ef97a6f9c0304bf",
      "value": " 0/19 [00:00&lt;?, ?it/s]"
     }
    },
    "8594dd4b83414a0cb8b2e9133d544c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f58b1e5a541d4fbd88afc495a7c63178",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb3bd4650dcf4f79b2caa6cce48607d5",
      "value": 0
     }
    },
    "97ae1940f1be4d948b8389b06fd95a89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3bb628c022b4e6ba6d46e27bd3a4533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab37bf0904184563ad69e45be02a441a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_339ac17a450d4d18b556a374370821c9",
       "IPY_MODEL_8594dd4b83414a0cb8b2e9133d544c98",
       "IPY_MODEL_f7a69a9e642547fb962ddb99ea4bd1a0"
      ],
      "layout": "IPY_MODEL_fe2b2f2d795640f0a805cc292303441c"
     }
    },
    "b8139b417062491387dbb8ae1a2af397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b954612735e84afbbb514760a7d88484": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb3bd4650dcf4f79b2caa6cce48607d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d443bd2a52294b7981e385876798a336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe6af7d2b7c84c65828edf7dba7c494c",
      "placeholder": "​",
      "style": "IPY_MODEL_65fe52f7f2cc498d95d15ffee087dde5",
      "value": "  0%"
     }
    },
    "f58b1e5a541d4fbd88afc495a7c63178": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7a69a9e642547fb962ddb99ea4bd1a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2430b9198c814ea499c5cb77b3c19c36",
      "placeholder": "​",
      "style": "IPY_MODEL_b8139b417062491387dbb8ae1a2af397",
      "value": " 0/10 [00:00&lt;?, ?it/s]"
     }
    },
    "fe2b2f2d795640f0a805cc292303441c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe6af7d2b7c84c65828edf7dba7c494c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
